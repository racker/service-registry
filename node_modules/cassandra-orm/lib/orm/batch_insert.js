/**
 *  Copyright 2012 Rackspace
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 *
 */

var util = require('util');
var events = require('events');

var async = require('async');
var log = require('logmagic').local('lib.orm.batch_insert');

var settings = require('../settings');
var BEGIN = require('./constants').BEGIN;
var DEFAULT_READ_CONSISTENCY = require('./constants').DEFAULT_READ_CONSISTENCY;
var DEFAULT_WRITE_CONSISTENCY = require('./constants').DEFAULT_WRITE_CONSISTENCY;
var COMMIT = require('./constants').COMMIT;
var REMOVED_FIELD = require('./constants').SPECIAL_FIELDS.removed;
var SPECIAL_FIELDS = require('./constants').SPECIAL_FIELDS;
var SCOPED_INDEX_TYPES = require('./constants').SCOPED_INDEX_TYPES;
var INDEX_KEY_DELIM = require('./constants').INDEX_KEY_DELIM;
var getConnPool = require('./utils').getConnPool;
var compoundColumn = require('./utils').compoundColumn;
var getIndexRowKey = require('./utils').getIndexRowKey;

var errors = require('../errors');


/**
 * Build a batch insert, it's a one shot deal, you create it once
 * and use it, once you do that it is unusable.
 * @constructor
 * @param {Context} ctx the context which to track.
 * @param {Context} key the key of the object batch inserted.
 * @param {?Object} options Options including 'writeConsistency' and 'writeTimestamp'.
 */
function BatchInsert(ctx, key, options) {
  options = options || {};

  this._key = key;
  this._ctx = ctx;
  this._txnId = ctx.txnId;
  this._query = [];
  this._args = [];
  this._preconditions = [];
  // Built for the indexes
  this._iquery = [];
  this._iargs = [];
  this._readConsistency = options.readConsistency || settings.DEFAULT_READ_CONSISTENCY;
  this._writeConsistency = options.writeConsistency || settings.DEFAULT_WRITE_CONSISTENCY;
  this._writeTimestamp = options.writeTimestamp;
  this.opened = false;
  this.committed = false;
  this._accounting = {};

  if (!key) {
    throw new Error('Missing "key" argument');
  }
}

/**
 * Start a transaction specify attributes to start the transaction.
 */
BatchInsert.prototype.begin = function() {
  this.opened = !this.opened;
  if (this.opened !== true) {
    throw new Error('Unable to open multiple batch inserts at a time');
  }

  log.dbg('Beginning new transaction', {'ctx': this._ctx, txnId: this._txnId});
};

/**
 * Save an object to the datastore.
 * @param {Dbobj} instance the instance of the database to save.
 * @param {?Number} ttl Optional TTL in seconds.
 */
BatchInsert.prototype.save = function(instance, ttl) {
  var cleaned = instance.toDb(), timeInMs = Date.now(), isNew = false;

  if (instance._type.meta.readOnly) {
    throw new Error('Trying to save a readOnly object');
  }

  instance.setRowKey(this._key);

  instance.updated_at = timeInMs;
  cleaned.cols[SPECIAL_FIELDS.updated_at] = timeInMs;

  if (!instance.hasOwnProperty('created_at')) {
    instance.created_at = timeInMs;
    cleaned.cols[SPECIAL_FIELDS.created_at] = timeInMs;
    isNew = true;
  } else {
    cleaned.cols[SPECIAL_FIELDS.created_at] = instance.created_at;
  }

  this._addIndexes(instance._type.meta, cleaned);
  this._save(instance._type, cleaned, isNew, ttl);
};

/**
 * Remove the index key.
 * @param {Object} indexObj the index object with properties that describe
 *                 the actual indexes themselves.
 * @param {Array.<string>} keys The specific keys to remove.
 * @param {Object} instance the DBBase object to act on.
 * @param {Object} meta the meta attributes.
 */
BatchInsert.prototype.removeIndex = function(indexObj, keys, instance, meta) {
  var cleaned = instance.toDb();

  if (meta.readOnly) {
    throw new Error('trying to save a readOnly object');
  }

  this._removeIndex(indexObj, keys, cleaned, meta);
};

/**
 * Remove the index key.
 * @param {Object} indexObj the index object with properties that describe
 *                 the actual indexes themselves.
 * @param {Array.<string>} keys The specific keys to remove.
 * @param {Object} cleaned Object to store, ({'key': key_name, 'parentKeys':[], 'cols': {...}}).
 * @param {Object} meta the meta attributes.
 */
BatchInsert.prototype._removeIndex = function(indexObj, keys, cleaned, meta) {
  var cn, query, key, rowKey, i;

  for (i = 0; i < keys.length; i++) {
    key = keys[i];

    if (['OneToMany', 'ScopedOneToMany'].indexOf(indexObj.relationship) !== -1) {
      cn = this._getIndexColumnName(indexObj, cleaned, meta, key);
      this._iargs.push(cn);
      query = 'DELETE ? FROM ? WHERE KEY=?;';
    }
    else if (indexObj.relationship === 'OneToOne') {
      query = 'DELETE FROM ? WHERE KEY=?;';
    }
    else {
      throw new Error('Unspecified index type for ' + indexObj);
    }

    rowKey = getIndexRowKey(this._key, indexObj, key);

    this._iquery.push(query);
    this._iargs.push(indexObj.meta.columnFamily, rowKey);
  }
};

/**
 * Soft or hard delete an object.
 * @param {Dbobj} instance the instance of the database to remove.
 * @param {String} type Deletion type. One of 'soft', 'hard'. Defaults to
 * 'soft'.
 */
BatchInsert.prototype.removeObject = function(instance, type) {
  type = type || 'soft';
  var cleaned = instance.toDb();

  if (instance._type.meta.readOnly) {
    throw new Error('Trying to remove a readOnly object');
  }

  if (['soft', 'hard'].indexOf(type) === -1) {
    throw new Error('Invalid delete type: ' + type);
  }

  // Remove indexes
  this._removeIndexes(instance._type.meta, cleaned);

  // Remove object
  if (type === 'soft') {
    this._softRemove(instance);
  }
  else if (type === 'hard') {
    this._hardRemove(instance);
  }
};

/**
 * Remove a whole key from the datastore.
 * @param {Dbobj} type the object type to remove.
 */
BatchInsert.prototype.removeKey = function(type) {
  if (type.meta.readOnly) {
    throw new Error('trying to removeKey a readOnly object');
  }

  this._removeKey(type.meta);
};

/**
 * Add accounting info to batch insert
 * @param {Object} act the accounting info, key is the counted type, value is plus or minus.
 */
BatchInsert.prototype.setAccountingInfo = function(act) {
  this._accounting = act;
};

/**
 * Save an object to the datastore.
 * @param {Object} type Object type.
 * @param {Object} obj Object to store, ({'key': key_name, 'parentKeys':[], 'cols': {...}}).
 * @param {boolean} isNew true if this is an update of an existent record.
 * @param {?Number} ttl Optional TTL in seconds.
 */
BatchInsert.prototype._save = function(type, obj, isNew, ttl) {
  ttl = ttl || null;
  var query,
      keyStr = null,
      meta = type.meta,
      database = meta.columnFamily,
      ttlStr = '';

  keyStr = type.getColKeyName(meta, obj);

  if (!ttl) {
    if (meta.ttl) {
      // ttl has been set for the datatype globally.
      ttl = meta.ttl;
    }

    if (this._ctx.account && this._ctx.account.ttl && this._ctx.account.ttl[meta.cname]) {
      // account ttl overwrites datatype ttl.
      // todo: we need to validate, streamline and standardize context creation so that we can rely on shit being there.
      ttl = this._ctx.account.ttl[meta.cname];
    }
  }

  if (ttl) {
    ttlStr = ' USING TTL ' + ttl;
  }

  query = 'UPDATE ?' + ttlStr + ' SET ?=? WHERE KEY=?;';
  // Add the list of arguments and queries, and then stringify the columns,
  // this is different from our typical serialization mechanism
  this._args.push(database, keyStr, JSON.stringify(obj.cols), this._key);
  this._query.push(query);
  log.trace('Adding query to batchSet', {ctx: this._ctx, query: query,
    txnId: this._txnId});

  // Update object counters when adding or removing objects.
  if (settings.TRACKED_MODELS.indexOf(meta.cname) !== -1) {
    if (isNew) {    // Increment
      this._query.push('UPDATE ? SET ? = ? + 1 WHERE KEY = ?');
      this._args.push(settings.ACCOUNTING_CF, meta.cname, meta.cname, this._key);
    } else if (obj.cols[REMOVED_FIELD]) {    // Decrement
      this._query.push('UPDATE ? SET ? = ? - 1 WHERE KEY = ?');
      this._args.push(settings.ACCOUNTING_CF, meta.cname, meta.cname, this._key);
    }
  }
};


/**
 * Mark object as deleted in the database..
 * @param {Dbobj} instance the instance of the database to remove.
 */
BatchInsert.prototype._softRemove = function(instance) {
  var cleaned = instance.toDb(), timeInMs = Date.now();

  cleaned.cols[REMOVED_FIELD] = true;

  cleaned.cols[SPECIAL_FIELDS.updated_at] = timeInMs;
  cleaned.cols[SPECIAL_FIELDS.created_at] = instance.created_at;
  cleaned.cols[SPECIAL_FIELDS.removed_at] = timeInMs;

  this._save(instance._type, cleaned, false, settings.SOFT_REMOVE_TTL);
};


/**
 * Remove object from a database.
 * @param {Dbobj} instance the instance of the database to remove.
 */
BatchInsert.prototype._hardRemove = function(instance) {
  var query, args, keyStr, cleaned = instance.toDb(),
      meta = instance._type.meta;

  keyStr = instance._type.getColKeyName(meta, cleaned);

  query = 'DELETE ? FROM ? WHERE KEY = ?';
  args = [keyStr, meta.columnFamily, this._key];
  this._query.push(query);
  this._args = this._args.concat(args);

  // Update object counters when adding or removing objects.
  if (settings.TRACKED_MODELS.indexOf(meta.cname) !== -1) {
    this._query.push('UPDATE ? SET ? = ? - 1 WHERE KEY = ?');
    this._args.push(settings.ACCOUNTING_CF, meta.cname, meta.cname, this._key);
  }
};

/**
 * Resolve the properties from a cleaned object based on the properties that
 * appear in the field.
 *
 * So this takes _a_ field like name: ['$ROWKEY', 'entity_id'] and processes it
 * against the current object (obj).
 * {
 *   key: 'foo',
 *   entity_id: 'enBar'
 * }
 *
 * and outputs -> 'foo:enBar'.
 *
 * It also respects the object type and it's dataPrefix (for cassandra
 * retrieval.
 *
 * @param {Array} field the field definition to resolve.
 * @param {Object} obj object with resolved fields to use for filling in.
 * @param {Object} meta object metadata.
 * @return {String} the resolved compound key.
 */
BatchInsert.prototype._resolveProperties = function(field, obj, meta) {
  var i,
      result = [];

  for (i = 0; i < field.length; i++) {
    this._resolveElement(field[i], obj, meta, result);
  }

  return compoundColumn(result);
};

/**
 * Resolve the element of the field. Reference above to the _resolveProperties
 * function to determine.
 *
 * @param {Object} element in the field.
 * @param {Object} obj object with resolved fields to use for filling in.
 * @param {Object} meta object metadata.
 * @param {Array} result the resulting array.
 */
BatchInsert.prototype._resolveElement = function(element, obj, meta, result) {
  var value;
  if (element === '$ROWKEY') {
    result.push(this._key);
  } else if (element === '$OBJKEY') {
    result.push(obj.key);
  } else {
    value = obj.cols[element];
    if (!value) {
      if (meta.parents) {
        value = meta.parents.indexOf(element);
        if (value !== -1) {
          result.push(obj.parentKeys[value]);
        }
      }
    } else {
      result.push(value);
    }
  }
};


/**
 * Return index column name.
 *
 * @param {Object} indexObj Index object.
 * @param {Object} attributes Object attributes.
 * @param {Object} meta Object meta attributes.
 * @param {String} indexKey Index key.
 * @return {String} Index column name.
 */
BatchInsert.prototype._getIndexColumnName = function(indexObj, attributes, meta, indexKey) {
  var cn = this._resolveProperties(indexObj.name, attributes, meta);

  if (SCOPED_INDEX_TYPES.indexOf(indexObj.relationship) !== -1) {
    cn = indexKey + INDEX_KEY_DELIM + cn;
  }

  return cn;
};


/**
 * Add a simple index entry, around the key.
 * @param {Object} indexObj the index object with properties that describe
 *                 the actual indexes themselves.
 * @param {Object} obj the object with column values to take on.
 * @param {Object} meta object metadata.
 */
BatchInsert.prototype._addIndex = function(indexObj, obj, meta) {
  var query,
      cn,
      cv,
      key,
      keys,
      i,
      self = this,
      indexRowKey,
      ttl = '';

  // This is used to test the precondition on a OneToOne index. It resides up
  // here because lint won't let us put it in the loop below.
  function oneToOnePreconditionTest(results) {
    if (results.rowCount() > 1) {
      return new errors.ExpectZeroOrOneRowsError();
    } else if (results.rowCount() === 0) {
      // this should never happen anymore, as selecting anything always returns at least the key.
      return null;
    } else {
      if (results[0].cols.length === 0) {
        // no collision.
        return null;
      } else if (results[0].cols.length > 1) {
        return new errors.ExpectZeroOrOneColumnError();
      } else if (results[0].cols.length > 0 && !results[0].colHash.hasOwnProperty(new Buffer(cn))) {
        // This is a really bad error so let's have really good log messages so we can diagnose.
        log.info('results returned with incorrect column name.', {ctx: self._ctx, colHash: results[0].colHash,
                                            expected: cn});
        return new errors.IndexCardinalityError();
      } else {
        return null;
      }
    }
  }

  keys = indexObj._getKeys(this, obj, meta);

  if (keys.length === 0) {
    // This short circuits if a key value on the object is empty (null / undefined)
    log.debug('Not adding index, keys is empty', {ctx: self._ctx, indexObj: indexObj});
    return;
  }

  for (i = 0; i < keys.length; i++) {
    key = keys[i];
    cn = this._getIndexColumnName(indexObj, obj, meta, key);

    indexRowKey = getIndexRowKey(this._key, indexObj, key);

    log.info('Adding index for at key: ' + key, {ctx: self._ctx, cn: cn, key: key, indexObj: indexObj, rowKey: indexRowKey});

    this._iargs.push(indexObj.meta.columnFamily, cn);

    if (indexObj.value) {
      if (meta.ttl) {
        ttl = ' USING TTL ' + meta.ttl;
      }

      if (this._ctx.account && this._ctx.account.ttl && this._ctx.account.ttl[meta.cname]) {
        ttl = ' USING TTL ' + this._ctx.account.ttl[meta.cname];
      }

      query = 'UPDATE ?' + ttl + ' SET ?=? WHERE KEY=?;';
      cv = this._resolveProperties(indexObj.value, obj, meta);
      this._iargs.push(cv);
    }
    else {
      query = 'UPDATE ? SET ?=NULL WHERE KEY=?;';
    }

    if (obj[key] === null) {
      // This is only reached if user specifies a custom _getKeys function. If
      // an object attribute is specified this will short circuit above because
      // _getKeys assigned on the index object inside cassandra_utils.js will
      // return empty string when calling bi._resolveProperties.
      log.debugf('Not adding index for key ${key}, because the object value is null', {ctx: self._ctx, key: key});
      continue;
    }

    this._iargs.push(indexRowKey);
    this._iquery.push(query);

    // if this is a 1:1 index, we need to check for cardinality constraint violations.
    if (indexObj.relationship === 'OneToOne') {
      this._preconditions.push({
        query: 'SELECT * FROM ? USING CONSISTENCY ' + this._readConsistency + ' WHERE KEY=?',
        args: [indexObj.meta.columnFamily, indexRowKey],
        test: oneToOnePreconditionTest
      });
    }
  }
};

/**
 * Add multiple indexes from the Object metadata
 * @param {Object} meta Name of the datastore to store it in.
 * @param {Object} obj Object to store, ({'key': key_name, 'parentKeys':[], 'cols': {...}}).
 */
BatchInsert.prototype._addIndexes = function(meta, obj) {
  if (meta.indexes) {
    var i,
        el;

    for (i in meta.indexes) {
      if (meta.indexes.hasOwnProperty(i)) {
        el = meta.indexes[i];
        this._addIndex(el, obj, meta);
      }
    }
  }
};

/**
 * Remove the indexes from a removed resource.
 * @param {Object} meta Name of the datastore to store it in.
 * @param {Object} obj Object to store, ({'key': key_name, 'parentKeys':[], 'cols': {...}}).
 */
BatchInsert.prototype._removeIndexes = function(meta, obj) {
  if (meta.indexes) {
    var i,
        el;

    for (i in meta.indexes) {
      if (meta.indexes.hasOwnProperty(i)) {
        el = meta.indexes[i];
        this._removeIndex(el, el._getKeys(this, obj, meta), obj, meta);
      }
    }
  }
};

/**
 * Remove a key from cassandra permanently
 * @param {Object} meta Meta information of the object type.
 */
BatchInsert.prototype._removeKey = function(meta) {
  var query,
      database = meta.columnFamily;

  if (meta.readOnly) {
    throw new Error('trying to remove a readOnly object');
  }

  query = 'DELETE FROM ? WHERE KEY=?;';
  // Add the list of arguments and queries
  this._args.push(database, this._key);
  this._query.push(query);
  log.trace('Adding remove-key query to batchSet', {ctx: this._ctx, query: query,
    txnId: this._txnId});
};

/**
 * This prep's the commit.  It can only be run once and it is an
 * internal method.  It sets a flag to prevent concurrent or more than one
 * runs of this.
 *
 * @param {Function} callback Callback on completion.
 */
BatchInsert.prototype._prepCommit = function(callback) {
  var query, args, key, options, usingClause;

  if (this.committed === true) {
    log.error('Already committed transaction, aborting.', {ctx: this._ctx, txnId: this._txnId});
    callback(new errors.DoubleCommitError());
    return;
  }
  for (key in this._accounting) {
    if (this._accounting.hasOwnProperty(key)) {
      if (this._accounting[key] > 0) {
        this._query.push('UPDATE ? SET ? = ? + 1 WHERE KEY = ?');
        this._args.push(settings.ACCOUNTING_CF, key, key, this._key);
      } else {
        this._query.push('UPDATE ? SET ? = ? - 1 WHERE KEY = ?');
        this._args.push(settings.ACCOUNTING_CF, key, key, this._key);
      }
    }
  }

  this.committed = true;
  query = this._iquery.concat(this._query);
  args = this._iargs.concat(this._args);
  options = [
    ['CONSISTENCY', this._writeConsistency]
  ];

  if (this._writeTimestamp !== undefined) {
    options.push(['TIMESTAMP', this._writeTimestamp]);
  }

  usingClause = 'USING ' + options.map(function(pair) {
    return pair.join(' ');
  }).join(' AND ');

  query = [BEGIN, usingClause, query.join(' '), COMMIT];
  callback(null, {query: query.join(' '), args: args});
};

/**
 * Commit the whole insert batch
 *
 * @param {function} callback Called with (err) when the object is committed.
 */
BatchInsert.prototype.commit = function(callback) {
  var self = this;

  async.waterfall([
    // drain all the preconditions.
    function drainPreconditions(callback) {
      async.forEachSeries(self._preconditions, function(obj, callback) {
        getConnPool().execute(self._ctx, obj.query, obj.args, function(err, results) {
          if (err) {
            callback(err);
          } else {
            // test will return error or null.
            callback(obj.test(results));
          }
        });
      }, function catchErrors(err) {
        callback(err);
      });
    },

    // prepare for committing.
    function prepCommit(callback) {
      self._prepCommit(function(err, qctx) {
        callback(err, qctx);
      });
    },

    // perform final query execution.
    function executeQuery(queryContext, callback) {
      if (self._query && self._query.length > 0) {
        getConnPool().execute(self._ctx, queryContext.query, queryContext.args, function(err, res) {
          log.trace('commit', { ctx: self._ctx, queryContext: queryContext });
          callback(err);
        });
      } else {
        callback();
      }
    }
  ], callback);
};

/**
 * Convenience method for putting together batch inserts
 */
exports.BatchInsert = BatchInsert;
